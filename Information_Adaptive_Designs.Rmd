---
title: "Untitled"
subtitle: "Untitled"
author: "Josh Betz (jbetz@jhu.edu)"
date: "2023-10-20"
output: html_fragment
bibliography:
  - "covariate_adjustment.bib"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

example_re <- 1.25
example_rcv <- (1/example_re) - 1
example_pcv <- 100*example_rcv
example_rcp <- example_re - 1
example_pcp <- 100*example_rcp
```

### Designing Precision Adaptive Randomized Trials

Investigators are faced with many challenges in designing efficient, ethical randomized trials due to many competing demands. A trial must collect enough information to identify meaningful benefits or harms with a desired probability, while also minimizing potential harm and suboptimal treatment of participants. Satisfying these competing demands is further complicated by the limited and imprecise information available during the design of a study.

Rather than planning analyses around sample sizes, investigators can plan analyses which occur when a specified level of precision is reached: this is known as information monitoring [@Mehta2001]. A precision-adaptive design can reduce the risk of under- or overpowered trials by collecting data until the precision is sufficient to conduct analyses. The precision of an estimator is simply the reciprocal of the variance of the estimator. Since this is unknown in practice, the variance is estimated using the square of the standard error of the estimator. 

We can estimate the precision required to achieve power $(1 - \beta)$ to identify a treatment effect $\delta$ with a $s$-sided test with type I error rate $\alpha$ using:

$$\mathcal{I} = \left(\frac{Z_{\alpha/s} + Z_{\beta}}{\delta}\right)^2 \approx \frac{1}{\left(SE(\hat{\delta})\right)^2} = \frac{1}{Var(\hat{\delta})}$$
This uses the square of the empirical standard error (or the empirical variance estimate) to measure the precision to which the treatment effect $\delta$ can be measured with the data in hand. A precision-adaptive design can reduce the risk of under- or overpowered trials by collecting data until the precision is sufficient to conduct analyses. 




--------------------------------------------------------------------------------




### Approximate Precision vs. Sample Size

Let $T$ denote treatment and $C$ denote control, and $Y^{(A)}$ denote the outcome of interest under treatment assigment $A$, where $A = 1$ indicates assignment to the treatment arm and $A = 0$ denotes assignment to the control arm.

For a continuous outcome, the required information to estimate the difference in means $\delta_{DIM} = E[Y^{(1)}] - E[Y^{(0)}]$ depends on the sample size and variances of outcomes in each treatment arm:

$$SE(\delta) = \sqrt{\frac{\sigma^{2}_{T}}{n_{T}} + \frac{\sigma^{2}_{C}}{n_{C}}}$$

For a binary outcome, the required information to estimate the risk difference $\delta_{RD} = E[Y^{(1)}] - E[Y^{(0)}]$ depends on the response rate in the control arm $(\pi_{C} = \pi_{T} - \delta)$:

$$SE(\delta) = \sqrt{\frac{\pi_{T}(1 - \pi_{T})}{n_{T}} + \frac{\pi_{C}(1 - \pi_{C})}{n_{C}}}$$ 

For an ordinal outcome with $K$ categories, let $\pi_{A}^{K} = Pr\{Y^{(A)} = k\}$ denote the probability of an outcome in category $k$ under treatment $A$. The Mann-Whitney estimand $\phi$ is the probability of having an outcome as good or better under the treatment arm relative to control with an adjustment for ties:

$$\phi = Pr\{Y^{(T)} > Y^{(C)}\} + \frac{1}{2} Pr\{Y^{(T)} = Y^{(C)}\}$$


This is also known as the competing probability. The precision/information depends on $\phi$ [@Fay2018]:

$$SE(\delta) \approx \sqrt{\frac{\phi(1 - \phi)}{n_{T}n_{C}}\left(1 + \left(\frac{n_{T} + n_{C} - 2}{2}\right)\left(\frac{\phi}{1 + \phi} + \frac{1 - \phi}{2 - \phi} \right)\right)}$$


Alternatively, the precision/information can be obtained from the distribution of outcomes under each treatment arm [@Zhao2008]. Let $N = n_{T} + n_{C}$:

$$SE(\delta) = \sqrt{\frac{1}{12(n_{T}n_{C})}\left(N+1 - \frac{1}{N(N-1)}\right)\sum_{k = 1}^{K}(\pi_{T}^{k}n_{T} + \pi_{C}^{k}n_{C})}$$

Expressions for other estimands can be obtained elsewhere [@Jennison1999]. In practice, the parameters in these expressions are not precisely known a priori. The advantage of an information-adaptive design is that the sample size is not fixed a priori based on estimates of these parameters, but adapts automatically to the precision of the accruing data.




--------------------------------------------------------------------------------




### Covariate Adjustment in Randomized Trials

Covariate adjusted analyses can also give greater precision than an unadjusted analyses without introducing more stringent assumptions, however the amount of precision gained in adjusted analyses are also not precisely known a priori [@Benkeser2020]. Instead of predicating the design on assumptions about the potential gain in precision from covariate adjustment, a precision-adaptive design automatically adjusts the sample size accordingly.

The relative efficiency of a covariate adjusted estimator to an unadjusted estimator is $RE_{A/U} = Var(\theta_{U})/Var(\theta_{A})$. The relative change in variance of a covariate-adjusted analysis to an unadjusted analysis is:

$$RCV_{A/U} = \frac{Var(\theta_{A}) - Var(\theta_{U})}{Var(\theta_{U})} = \frac{1}{RE_{A/U}} - 1$$
Alternatively, $RE_{A/U} = 1/(1 + RCV_{A/U})$: If a covariate adjusted analysis has a relative efficiency of `r example_re`, the relative change in variance would be `r example_rcv`, or a `r paste0(example_pcv, "%")` change in variance. Since precision is the inverse of variance, the relative change in precision of a covariate-adjusted analysis to an unadjusted analysis is:

$$RCP_{A/U} = \frac{1/Var(\theta_{A}) - 1/Var(\theta_{U})}{1/Var(\theta_{U})} = Var(\theta_{U})/Var(\theta_{A}) - 1 = RE_{A/U} - 1$$
Alternatively, $RE_{A/U} = 1 + RCP_{A/U}$: If a covariate adjusted analysis has a relative efficiency of `r example_re`, the relative change in precision would be `r example_rcp`, or a `r paste0(example_pcp, "%")` change in precision.




--------------------------------------------------------------------------------




### Sequential Analyses

Pre-planned interim analyses allow investigators to stop a randomized trial early for efficacy or futility [@Jennison1999]. Precision-adaptive trials can integrate both interim analyses and covariate adjustment, using a broad class of methods [@VanLancker2022]. @Mehta2001 illustrate information-adaptive designs in practice. For a tutorial on implementing interim analyses, see @Lakens2021.



### References
